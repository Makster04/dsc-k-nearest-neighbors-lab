{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, you'll build a simple version of a **_K-Nearest Neigbors classifier_** from scratch, and train it to make predictions on a dataset!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "* Implement a basic KNN algorithm from scratch\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "You'll begin this lab by creating a classifier. To keep things simple, you'll be using a helper function, `euclidean()`, from the `spatial.distance` module of the `scipy` library. Import this function in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the `KNN` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now: \n",
    "\n",
    "* Create an class called `KNN` \n",
    "* This class should contain two empty methods -- `fit` and `predict` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KNN class with two empty methods - fit and predict\n",
    "class KNN:\n",
    "\n",
    "    def fit():\n",
    "        pass\n",
    "\n",
    "    def predict():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comple the `fit()` method\n",
    "\n",
    "Recall that when \"fitting\" a KNN classifier, all you're really doing is storing the points and their corresponding labels. There's no actual \"fitting\" involved here, since all you need to do is store the data so that you can use it to calculate the nearest neighbors when the `predict()` method is called.\n",
    "\n",
    "The inputs for this function should be:\n",
    "\n",
    "* `self`: since this will be an instance method inside the `KNN` class \n",
    "* `X_train`: an array, each row represents a _vector_ for a given point in space  \n",
    "* `y_train`: the corresponding labels for each vector in `X_train`. The label at `y_train[0]` is the label that corresponds to the vector at `X_train[0]`, and so on  \n",
    "\n",
    "In the cell below, complete the `fit` method:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X_train, y_train):\n",
    "    self.X_train = X_train\n",
    "    self.y_train = y_train\n",
    "\n",
    "# This line updates the knn.fit method to point to the function you've just written\n",
    "KNN.fit = fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "Next, you will write three helper functions to make things easier when completing the `predict()` method. \n",
    "\n",
    "In the cell below, complete the `_get_distances()` function. This function should:\n",
    "\n",
    "* Take in two arguments: `self` and `x`\n",
    "* Create an empty array, `distances`, to hold all the distances you're going to calculate\n",
    "* Enumerate through every item in `self.X_train`. For each item: \n",
    "    * Use the `euclidean()` function to get the distance between x and the current point from `X_train` \n",
    "    * Create a tuple containing the index and the distance (in that order!) and append it to the `distances` array \n",
    "* Return the `distances` array when a distance has been generated for all items in `self.X_train` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_distances(self, x):\n",
    "    distances = []\n",
    "    for i, train_point in enumerate(self.X_train):\n",
    "        dist = euclidean(x, train_point)\n",
    "        distances.append((i, dist))\n",
    "    return distances\n",
    "# This line attaches the function you just created as a method to KNN class \n",
    "KNN._get_distances = _get_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! You will now create a `_get_k_nearest()` function to retrieve indices of the k-nearest points. This function should:\n",
    "\n",
    "* Take three arguments:\n",
    "    * `self`\n",
    "    * `dists`: an array of tuples containing (index, distance), which will be output from the `_get_distances()` method. \n",
    "    * `k`: the number of nearest neighbors you want to return\n",
    "* Sort the `dists` array by distances values, which are the second element in each tuple\n",
    "* Return the first `k` tuples from the sorted array \n",
    "\n",
    "**_Hint:_** To easily sort on the second item in the tuples contained within the `dists` array, use the `sorted()` function and pass in lambda for the `key=` parameter. To sort on the second element of each tuple, you can just use `key=lambda x: x[1]`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_k_nearest(self, dists, k):\n",
    "    sorted_dists = sorted(dists, key=lambda x: x[1])\n",
    "    return sorted_dists[:k]\n",
    "\n",
    "\n",
    "# This line attaches the function you just created as a method to KNN class \n",
    "KNN._get_k_nearest = _get_k_nearest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final helper function you'll create will get the labels that correspond to each of the k-nearest point, and return the class that occurs the most. \n",
    "\n",
    "Complete the `_get_label_prediction()` function in the cell below. This function should:\n",
    "\n",
    "* Create a list containing the labels from `self.y_train` for each index in `k_nearest` (remember, each item in `k_nearest` is a tuple, and the index is stored as the first item in each tuple)\n",
    "* Get the total counts for each label (use `np.bincount()` and pass in the label array created in the previous step)\n",
    "* Get the index of the label with the highest overall count in counts (use `np.argmax()` for this, and pass in the counts created in the previous step) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_label_prediction(self, k_nearest):\n",
    "    labels = [self.y_train[i] for i, _ in k_nearest]\n",
    "    counts = np.bincount(labels)\n",
    "    return np.argmax(counts)\n",
    "\n",
    "# This line attaches the function you just created as a method to KNN class\n",
    "KNN._get_label_prediction = _get_label_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now, you now have all the ingredients needed to complete the `predict()` method.\n",
    "\n",
    "## Complete the `predict()` method\n",
    "\n",
    "This method does all the heavy lifting for KNN, so this will be a bit more complex than the `fit()` method. Here's an outline of how this method should work:\n",
    "\n",
    "* In addition to `self`, our `predict` function should take in two arguments: \n",
    "    * `X_test`: the points we want to classify\n",
    "    * `k`: which specifies the number of neighbors we should use to make the classification.  Set `k=3` as a default, but allow the user to update it if they choose \n",
    "* Your method will need to iterate through every item in `X_test`. For each item:\n",
    "    * Calculate the distance to all points in `X_train` by using the `._get_distances()` helper method \n",
    "    * Find the k-nearest points in `X_train` by using the `._get_k_nearest()` method \n",
    "    * Use the index values contained within the tuples returned by `._get_k_nearest()` method to get the corresponding labels for each of the nearest points  \n",
    "    * Determine which class is most represented in these labels and treat that as the prediction for this point. Append the prediction to `preds` \n",
    "* Once a prediction has been generated for every item in `X_test`, return `preds`\n",
    "\n",
    "Follow these instructions to complete the `predict()` method in the cell below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X_test, k=3):\n",
    "    preds = []\n",
    "    for x in X_test:\n",
    "        dists = self._get_distances(x)\n",
    "        k_nearest = self._get_k_nearest(dists, k)\n",
    "        pred_label = self._get_label_prediction(k_nearest)\n",
    "        preds.append(pred_label)\n",
    "    return preds\n",
    "\n",
    "# This line updates the knn.predict method to point to the function you've just written\n",
    "KNN.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now, try out your new KNN classifier on a sample dataset to see how well it works!\n",
    "\n",
    "## Test the KNN classifier\n",
    "\n",
    "In order to test the performance of your model, import the **_Iris dataset_**. Specifically: \n",
    "\n",
    "- Use the `load_iris()` function, which can be found inside of the `sklearn.datasets` module. Then call this function, and use the object it returns \n",
    "- Import `train_test_split()` from `sklearn.model_selection`, as well as `accuracy_score()` from `sklearn.metrics` \n",
    "- Assign the `.data` attribute of `iris` to `data` and the `.target` attribute to `target` \n",
    "\n",
    "Note that there are **_3 classes_** in the Iris dataset, making this a multi-categorical classification problem. This means that you can't use evaluation metrics that are meant for binary classification problems. For this, just stick to accuracy for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_iris' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Iris dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m iris \u001b[38;5;241m=\u001b[39m \u001b[43mload_iris\u001b[49m()\n\u001b[0;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m iris\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m      4\u001b[0m target \u001b[38;5;241m=\u001b[39m iris\u001b[38;5;241m.\u001b[39mtarget\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_iris' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `train_test_split()` to split the data into training and test sets. Pass in the `data` and `target`, and set the `test_size` to 0.25 and `random_state` to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Split dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(\n\u001b[0;32m      3\u001b[0m     data, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate the `KNN` class, and `fit` it to the data in `X_train` and the labels in `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit KNN\n",
    "knn = KNN()\n",
    "knn.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, use the `.predict()` method to generate predictions for the data stored in `X_test`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate predictions\n",
    "preds = knn.predict(X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the moment of truth! Test the accuracy of your predictions. In the cell below, complete the call to `accuracy_score()` by passing in `y_test` and `preds`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate accuracy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m(y_test, preds)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting Accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(accuracy))\u001b[38;5;66;03m# Expected Output: Testing Accuracy: 0.9736842105263158\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"Testing Accuracy: {}\".format(accuracy))# Expected Output: Testing Accuracy: 0.9736842105263158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 97% accuracy! Not bad for a handwritten machine learning classifier!\n",
    "\n",
    "## Summary\n",
    "\n",
    "That was great! Next, you'll dive a little deeper into evaluating performance of a KNN algorithm!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
